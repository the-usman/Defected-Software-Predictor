{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/playground-series-s3e23/data\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col=[0])\n",
    "\n",
    "def Overview (data) :\n",
    "    profile = ProfileReport(dark_mode=True, df=data)\n",
    "    profile.to_file(\"output.html\")\n",
    "\n",
    "# Overview(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis \n",
    "\n",
    "# As data is to much long so we use sample of data to analyze\n",
    "\n",
    "# Creating Sample \n",
    "\n",
    "sample_data = data.sample(10000)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Univarient Data analysis\n",
    "\n",
    "def UnivariateAnalysis(data, column):\n",
    "    plt.figure(figsize=(12, 6))  \n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.histplot(data=data, x=column)\n",
    "    plt.title(f'Countplot of {column}')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    data[column].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title(f'Pie Chart of {column}')\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnivariateAnalysis(sample_data, 'defects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = sample_data.corr()['defects'].sort_values(ascending=False).drop(['defects'])\n",
    "corr_df = pd.concat([corr_df.head(10), corr_df.tail(1)])\n",
    "corr_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in corr_df.index :\n",
    "    UnivariateAnalysis(sample_data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This show the very much skewness in data to check actual skewness we stats.probplot\n",
    "\n",
    "from scipy import stats\n",
    "def CheckSkewness(data, column):\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.kdeplot(data[column]) \n",
    "    plt.title(\"Density Plot on \" + column) \n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "    stats.probplot(data[column], dist='norm', plot=plt)\n",
    "    plt.title(f\"Q-Q Plot of {column}\")\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckSkewness(sample_data, 'loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in corr_df.index :\n",
    "    CheckSkewness(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These all are skew so we should go to the bining technique\n",
    "for column in data.columns :\n",
    "    print(column)\n",
    "    print(data[column].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data.drop(['defects'], axis=1)\n",
    "targets = data.defects\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "targets = le.fit_transform(targets)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer([\n",
    "    (\"power\", PowerTransformer(), ['loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e', 'b', 't','lOCode', 'lOComment', 'lOBlank', 'locCodeAndComment', 'uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount'])\n",
    "], remainder='passthrough', verbose_feature_names_out=False).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trf2 = ColumnTransformer([\n",
    "    (\"function\", FunctionTransformer(func=np.log1p), ['loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e', 'b', 't','lOCode', 'lOComment', 'lOBlank', 'locCodeAndComment', 'uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount'])\n",
    "], remainder='passthrough', verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "X_train = trf2.fit_transform(X_train)\n",
    "X_train\n",
    "X_test = trf2.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X_train.columns :\n",
    "    \n",
    "    CheckSkewness(X_train, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now data is skew \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel () :\n",
    "\n",
    "    lgb_dict = {\n",
    "        \"learning_rate\" : 0.2,\n",
    "        \"n_estimators\" : 200,\n",
    "        \"boosting_type\" : 'dart',\n",
    "        \"reg_alpha\" : 0.4,\n",
    "    }\n",
    "\n",
    "    xgb_dict = {\n",
    "        \"n_estimators\" : 200,\n",
    "        \"learning_rate\" : 0.2,\n",
    "        \"eval_metric\" : 'auc',\n",
    "        \"objective\" : \"binary:logistic\"\n",
    "    }\n",
    "\n",
    "    cat_dict = {\n",
    "        \"n_estimators\" : 200,\n",
    "        \"learning_rate\" : 0.2\n",
    "    }\n",
    "\n",
    "    model_dict = {\n",
    "        \"log\" : LogisticRegression(max_iter=1000),\n",
    "        \"lgb\" : LGBMClassifier(random_state=42, **lgb_dict),\n",
    "        \"cat\" : CatBoostClassifier(random_state=42, verbose=False, **cat_dict),\n",
    "        \"xgb\" : XGBClassifier(random_state=42, **xgb_dict),\n",
    "    }\n",
    "\n",
    "    model_score = []\n",
    "\n",
    "    for model_name, model in model_dict.items() :\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        roc_auc = roc_auc_score(y_test, pred)\n",
    "        print(f\"ROC AUC Score of model {model_name}:\", roc_auc)\n",
    "        model_score.append(roc_auc)\n",
    "\n",
    "\n",
    "TrainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def KNNModel (X_test, X_train, y_train, y_test) :\n",
    "    X_train = X_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    knn = KNeighborsClassifier(n_neighbors=200)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC Score of model :\", roc_auc)\n",
    "\n",
    "\n",
    "KNNModel(X_test, X_train,y_train,  y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trf2.fit_transform(inputs)\n",
    "test_data = trf2.transform(test_data)\n",
    "model = LGBMClassifier(random_state=42)\n",
    "model.fit(data, targets)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_data)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "len(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['defects'] = y_pred\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
